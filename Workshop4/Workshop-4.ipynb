{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee59c11d",
   "metadata": {},
   "source": [
    "## Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf491537",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Apple provides an api to get some useful information from iTunes and Apple Book Store content. \n",
    "You can read more details about this service <a href=\"https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/\">here</a>. In this mini project, we will use the mentioned service to get info. about the first 50 audio books that talks about data from Apple store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c117d",
   "metadata": {},
   "source": [
    "### Step .1\n",
    "- Fetch the data from using the following URL: https://itunes.apple.com/search?term=data&country=us&entity=audiobook&limit=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd642bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://itunes.apple.com/search?term=data&country=us&entity=audiobook&limit=50\"\n",
    "data = requests.get(url)\n",
    "\n",
    "json_data = data.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af3c4f",
   "metadata": {},
   "source": [
    "### Step .2\n",
    "- Save these data into a DataFrame that should look as follows (extract the required data only):\n",
    "\n",
    "|    | artistName    | collectionName                                                                                         | releaseDate          | primaryGenreName            |   collectionPrice | collectionViewUrl                                                                                         |\n",
    "|---:|:--------------|:-------------------------------------------------------------------------------------------------------|:---------------------|:----------------------------|------------------:|:----------------------------------------------------------------------------------------------------------|\n",
    "|  0 | Emily Oster   | Cribsheet: A Data-Driven Guide to Better, More Relaxed Parenting, from Birth to Preschool (Unabridged) | 2019-04-23T07:00:00Z | Nonfiction                  |             14.99 | https://books.apple.com/us/audiobook/cribsheet-a-data-driven-guide-to-better-more/id1459654300?uo=4       |\n",
    "|  1 | George Gilder | Life After Google: The Fall of Big Data and the Rise of the Blockchain Economy                         | 2018-07-17T07:00:00Z | Business & Personal Finance |             14.99 | https://books.apple.com/us/audiobook/life-after-google-the-fall-of-big-data-and/id1454667331?uo=4         |\n",
    "|  .. | ...  | ...    | ... | ...  | ... | ... |\n",
    "| 49 | William Sullivan | SQL Data Warehouse Database Management, SQL Server, Structured Query Language, Business Intelligence, Data Models: Master SQL Programming (Unabridged) | 2018-05-14T07:00:00Z | Science & Nature   |              5.99 | https://books.apple.com/us/audiobook/sql-data-warehouse-database-management-sql-server-structured/id1385009049?uo=4 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73049472",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your Code Here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.10/site-packages/pandas/io/json/_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.10/site-packages/pandas/io/json/_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.10/site-packages/pandas/io/json/_json.py:944\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    937\u001b[0m filepath_or_buffer \u001b[38;5;241m=\u001b[39m stringify_path(filepath_or_buffer)\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_url(filepath_or_buffer)\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_fsspec_url(filepath_or_buffer)\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    943\u001b[0m ):\n\u001b[0;32m--> 944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    959\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/Desktop/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:472\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    470\u001b[0m ):\n\u001b[1;32m    471\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(filepath_or_buffer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[1;32m    475\u001b[0m     filepath_or_buffer\u001b[38;5;241m=\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    476\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    480\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'dict'>"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed16fbb",
   "metadata": {},
   "source": [
    "### Step .3\n",
    "- Rename the dataframe columns to be: `'author','collectionName','date','genre','price','url'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf24c53",
   "metadata": {},
   "source": [
    "### Step .4\n",
    "- Your dataFrame doesn't contain some importat data. such as (`the name of the narrator`, and `the length of the audiobook`).\n",
    "So add this data to each book in the dataframe, by fetching and extracting it from the audiobook `url` that exist in your dataframe for each book\n",
    "\n",
    "**Hints:** \n",
    "   - Write code to visit each url, find the div with the class `book-badge__value` in that url, then you will get all these values in a list.\n",
    "   - You can use `df[col_name].apply(function_name)` to apply certain function on each value in a certain column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354ee54",
   "metadata": {},
   "source": [
    "### Step .5\n",
    "- In the column date keep only the year\n",
    "- Convert `year` into `int` datatype and `price` to `float` datatype\n",
    "- Remove the column `url` from the dataframe as it is not required anymore\n",
    "\n",
    "Your dataFrame should look as follows:\n",
    "\n",
    "|    | author        | collectionName                                                                                         |   date | genre                       |   price | narrator   | length   |\n",
    "|---:|:--------------|:-------------------------------------------------------------------------------------------------------|-------:|:----------------------------|--------:|:-----------|:---------|\n",
    "|  0 | Emily Oster   | Cribsheet: A Data-Driven Guide to Better, More Relaxed Parenting, from Birth to Preschool (Unabridged) |   2019 | Nonfiction                  |   14.99 | KV         | 10:36    |\n",
    "|  1 | George Gilder | Life After Google: The Fall of Big Data and the Rise of the Blockchain Economy                         |   2018 | Business & Personal Finance |   14.99 | EMS        | 09:38    |\n",
    "|  .. | ...  | ...    | ... | ...  | ... | \n",
    "| 49 | William Sullivan | SQL Data Warehouse Database Management, SQL Server, Structured Query Language, Business Intelligence, Data Models: Master SQL Programming (Unabridged) |   2018 | Science & Nature |    5.99 | LH         | 02:49    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309144c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0153aae",
   "metadata": {},
   "source": [
    "### Step .6\n",
    "- Find the number of audiobooks pubished before year 2015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef0a55",
   "metadata": {},
   "source": [
    "### Step .7\n",
    "- Find the name of the author who has the largest number of audiobooks\n",
    "- Find the all audiobooks of that author and show their genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce995bd",
   "metadata": {},
   "source": [
    "### Step .8\n",
    "- Find the title of the most expensive collection\n",
    "- Find the name of the narrator who has the longest audiobook\n",
    "- Find the number of diffenet genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e848c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90ee7e",
   "metadata": {},
   "source": [
    "### Step .9\n",
    "- Compare the mean price of different genre\n",
    "- Compare the mean price of different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c2cc8",
   "metadata": {},
   "source": [
    "### Step .10\n",
    "- Find the year that has the highest number of Nonfiction audiobooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b22e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2aaa2",
   "metadata": {},
   "source": [
    "### Step .11\n",
    "- Compare (visually) between the number of books in different genre (make sure that your chart is meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ebe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37b23c",
   "metadata": {},
   "source": [
    "### Step .12\n",
    "- Compare (visually) between the number of books published in different years (make sure that your chart is meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d3600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
